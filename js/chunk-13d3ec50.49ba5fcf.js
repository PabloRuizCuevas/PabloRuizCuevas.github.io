(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-13d3ec50"],{"53ef":function(e,t,a){},6979:function(e,t,a){"use strict";a("53ef")},"85b0":function(e,t,a){"use strict";a.r(t);var i=a("7a23"),n=Object(i["P"])("data-v-747f37be");Object(i["w"])("data-v-747f37be");var o={class:"page"},c=Object(i["g"])('<main data-v-747f37be><div class="article" data-v-747f37be><h1 data-v-747f37be> Image analysis</h1><p data-v-747f37be> We can calculate the reduction factor $R$ of the real images we get in the detector by analyzing them. First we need to take the image from the mira detector and convert it to a matrix, we crop the image in the place we observe most of the neutrons collide, in the case we analize here we can observe clearly the footprint of the cilinder of nikel we used as a sample.</p><div class="image_container" data-v-747f37be><img alt="Figure" src="/images/image2.png" data-v-747f37be><figcaption data-v-747f37be> Image of one of the 16 detector plates.</figcaption></div><p data-v-747f37be> The neutron detector consist has a total of 16 neutron sensitive layers, and therefore we have 16 of this images.The intensity they receive will depend on the reduction factor we have calculated in previos articles and in general it depends in the path length difference between the neutrons, the spin precesion of the neutron will lead to path differences causing destructive or constructive interferences that can be detected. </p><div class="image_container" data-v-747f37be><img alt="Figure" src="/images/image.png" data-v-747f37be><figcaption data-v-747f37be> Croped image of one of the 16 detector plates.</figcaption></div><p data-v-747f37be> The reduction factor in our case will depend on the contrast and can be calculated by fitting our data by an armonic function. </p><p class="equation" data-v-747f37be> $$ A * sin(bx+c)$$ </p><p data-v-747f37be> The reduction factor varies sligthly for each part of the image, but we can assume it more or less constant, taking the 16 images and summing up their intensity we can simply make a fit that will </p><div class="image_container" data-v-747f37be><img alt="Figure" src="/images/fit.png" data-v-747f37be><figcaption data-v-747f37be> Croped image of one of the 16 detector plates.</figcaption></div><p data-v-747f37be> Finall the contrast is calculated using the fitted values of the armonic equation: </p><p class="equation" data-v-747f37be> $$ R = \\frac{ |A| }{c} $$ </p><p data-v-747f37be> To fit the equation we can simply use any python library, the error will be also given by the fit. </p><p data-v-747f37be> If we need an alternative method to get more precision, specially if the difference of travel path between the different part of the images is not neglectable, we have developed a method inspired in the boostrap method. We will make a second crop in the image to analyze and calculate the reduction factor of this second crop, we repeat this procces for randomly generated crops of different size, depending in our necesities, and we can calculate the final contrast as the average value of all the crops. The error in this case is calculated using the sample standard deviation. In practice, for our case, this method didn&#39;t decrease the error but gave us a sligthly bigger contrast. </p><div class="image_container" data-v-747f37be><img alt="Figure" src="/images/histogram.png" data-v-747f37be><figcaption data-v-747f37be> The outcome of the constrast calculated over 50000 calculations with different crops of the image. </figcaption></div><p data-v-747f37be> In the code we serve in this page to dowload you can a jupiter notebook with exemplary data and the fits we have seen here. </p></div></main>',1);Object(i["u"])();var r=n((function(e,t,a,n,r,s){return Object(i["t"])(),Object(i["e"])("div",o,[c])})),s={name:"Latexpage4",methods:{reRender:function(){window.MathJax&&(console.log("rendering mathjax"),window.MathJax.Hub.Queue(["Typeset",window.MathJax.Hub],(function(){return console.log("done")})))}},mounted:function(){this.reRender()}};a("6979");s.render=r,s.__scopeId="data-v-747f37be";t["default"]=s}}]);
//# sourceMappingURL=chunk-13d3ec50.49ba5fcf.js.map